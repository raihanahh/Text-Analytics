{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210d72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f0e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news_dataset.csv')\n",
    "texts = df['text'].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4d1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords and non-alphabetic characters, lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the texts\n",
    "processed_texts = [preprocess_text(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000d397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(processed_texts)\n",
    "# Filter out extremes to limit the number of features\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# Create a corpus: Term Document Frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e460aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for LDA\n",
    "num_topics = 4  # Number of topics\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=100,\n",
    "                     update_every=1,\n",
    "                     chunksize=100,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efb3421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5945879818788151\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c8a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"key\" + 0.016*\"encryption\" + 0.016*\"chip\" + 0.014*\"db\" + 0.012*\"system\" + 0.012*\"use\" + 0.010*\"information\" + 0.009*\"privacy\" + 0.009*\"clipper\" + 0.008*\"file\"')\n",
      "(1, '0.013*\"armenian\" + 0.007*\"administration\" + 0.006*\"enforcement\" + 0.006*\"two\" + 0.005*\"use\" + 0.005*\"block\" + 0.005*\"system\" + 0.005*\"state\" + 0.005*\"one\" + 0.005*\"start\"')\n",
      "(2, '0.198*\"q\" + 0.087*\"x\" + 0.081*\"n\" + 0.069*\"e\" + 0.049*\"k\" + 0.037*\"c\" + 0.035*\"p\" + 0.026*\"f\" + 0.024*\"r\" + 0.023*\"g\"')\n",
      "(3, '0.013*\"would\" + 0.012*\"people\" + 0.010*\"one\" + 0.007*\"government\" + 0.007*\"think\" + 0.007*\"know\" + 0.006*\"right\" + 0.006*\"say\" + 0.006*\"u\" + 0.005*\"could\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb08338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Despite the initial topic having a lot of noise, the topics of the LDA model show important patterns across the dataset. \n",
    "#Topic 1 likely to focus on legal and political matters, as indicated by terms like \"people,\" \"government,\" and \"law.\" \n",
    "#Topic 2 is less formal and more conversational, with words like \"would,\" \"like,\" and \"know,\" which allude to general discussions or opinions.\n",
    "#Topic 3 is about technology and encryption, as evidenced by terms like \"chip,\" \"key,\" and \"encryption.\" \n",
    "#The first subject may indicate preprocessing issues or non-standard material because it appears to include random characters and symbols.\n",
    "#A moderate level of interpretability and coherence across the topics is indicated by the coherence score of 0.5347, suggesting that while the model has identified some pertinent themes, there is still room for improvement, especially in terms of addressing data noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
